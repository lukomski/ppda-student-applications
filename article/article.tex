\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Comparison of three selected ML models for predicting decision of the Dean}

\author{\IEEEauthorblockN{inż. Jan Łukomski}
\IEEEauthorblockA{\textit{Faculty of Electrical Engineering} \\
\textit{Warsaw University of Technology}\\
Warsaw, Poland}
\and
\IEEEauthorblockN{inż. Paweł Podgórski}
\IEEEauthorblockA{\textit{Faculty of Electrical Engineering} \\
\textit{Warsaw University of Technology}\\
Warsaw, Poland}
}

\maketitle

\input{text/00_abstract}

\begin{IEEEkeywords}
ml, svm, knn, decision tree classifier
\end{IEEEkeywords}

\input{text/main}


\begin{thebibliography}{00}
% literature section should contain at least 4 to 5 positions from Google Scholar!
\bibitem{sklearn} https://scikit-learn.org/stable/tutorial/machine\_learning\_map/index.html
\bibitem{towards_class} https://towardsdatascience.com/top-10-binary-classification-algorithms-a-beginners-guide-feeacbd7a3e2
\bibitem{Zou} Zou, H. (2019). Classification with high dimensional features. Wiley Interdisciplinary Reviews: Computational Statistics, 11(1), e1453.
\bibitem{tomaszkacmajor} https://tomaszkacmajor.pl/index.php/2016/04/17/support-vector-machine/https://tomaszkacmajor.pl/index.php/2016/04/17/support-vector-machine/
\bibitem{PMC5822181} https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5822181/
\bibitem{ibm_trees_decision_tree} https://www.ibm.com/docs/pl/spss-modeler/saas?topic=trees-decision-tree-models
\bibitem{sklearn_tree} https://scikit-learn.org/stable/modules/tree.html
\bibitem{Kotsiantis} Kotsiantis, S. B. (2013). Decision trees: a recent overview. Artificial Intelligence Review, 39(4), 261–283. https://doi.org/10.1007/s10462-011-9272-4
\bibitem{AbuAlfeilat} Abu Alfeilat, H. A., Hassanat, A. B. A., Lasassmeh, O., Tarawneh, A. S., Alhasanat, M. B., Eyal Salman, H. S., \& Prasath, V. B. S (2019). Effects of Distance Measure Choice on K-Nearest Neighbor Classifier Performance: A Review [Doi: 10.1089/big.2018.0175]. Big Data, 7(4), 221–248. https://doi.org/10.1089/big.2018.0175
\bibitem{Tsoumakas} Tsoumakas, G., Katakis, I., \& Vlahavas, I. (2006, September). A review of multi-label classification methods. In Proceedings of the 2nd ADBIS workshop on data mining and knowledge discovery (ADMKD 2006) (pp. 99-109).
\bibitem{Syaliman} Syaliman, K. U. (2021). Enhance the Accuracy of K-Nearest Neighbor (K-Nn) for Unbalanced Class Data Using Synthetic Minority Oversampling Technique (Smote) and Gain Ratio (Gr). INFOKUM, 10(1), 188-195.

\end{thebibliography}

\end{document}