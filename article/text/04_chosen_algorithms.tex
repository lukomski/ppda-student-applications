% selection and short theoretical description of two algorithms for the evaluation
% description of the benchmarking experiment - what are you going to check, verify and how you are going to get reasonable the results (eg. performance (classification metrics)),
According to sklearn library recomandation \cite{sklearn} and \cite{towards_class}, we choose to test dataset with SVM model, Decision Tree Classifier and with KNN Classificator.
% generated - to be fixed
The experiment will proceed in several steps. Firstly, the dataset will be preprocessed, involving tasks such as data cleaning, handling missing values, and feature engineering. This step is crucial in ensuring the quality and integrity of the data used for training and testing the ML models.
Next, the dataset will be divided into training and testing sets using an appropriate splitting technique, such as stratified sampling, to maintain the distribution of positive and negative decisions in both sets. The training set will be used to train the ML models, while the testing set will be kept separate and used later for evaluating the models' performance.
Each ML model (SVM, Decision Tree Classifier, and KNN Classifier) will then be trained on the training set using suitable hyperparameter tuning techniques to optimize their performance. Cross-validation may also be employed to estimate the models' generalization capabilities.
Once the models are trained, they will be evaluated using various performance metrics, including accuracy, precision, recall, and F1 score. These metrics provide a comprehensive understanding of the models' predictive capabilities and their ability to correctly classify positive and negative decisions made by the Dean.